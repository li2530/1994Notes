@Book{royden1988real,
  title={Real analysis},
  author={Royden, Halsey Lawrence and Fitzpatrick, Patrick},
  volume={32},
  year={1988},
  publisher={Macmillan New York}
}

@Book{lasota1998chaos,
  title={Chaos, fractals, and noise: stochastic aspects of dynamics},
  author={Lasota, Andrzej and Mackey, Michael C},
  volume={97},
  year={1998},
  publisher={Springer Science \& Business Media}
}
@InProceedings{QianxiaoLiWeinanE2017SME,
  title = 	 {Stochastic Modified Equations and Adaptive Stochastic Gradient Algorithms},
  author =       {Qianxiao Li and Cheng Tai and Weinan E},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2101--2110},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/li17f/li17f.pdf},
  url = 	 {https://proceedings.mlr.press/v70/li17f.html},
  abstract = 	 {We develop the method of stochastic modified equations (SME), in which stochastic gradient algorithms are approximated in the weak sense by continuous-time stochastic differential equations. We exploit the continuous formulation together with optimal control theory to derive novel adaptive hyper-parameter adjustment policies. Our algorithms have competitive performance with the added benefit of being robust to varying models and datasets. This provides a general methodology for the analysis and design of stochastic gradient algorithms.}
}
@InProceedings{
SmithBarrett2021ImplicitReularizationStochasticGD,
title={On the Origin of Implicit Regularization in Stochastic Gradient Descent},
author={Samuel L Smith and Benoit Dherin and David Barrett and Soham De},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=rq_Qr0c1Hyo}
}
@InProceedings{Jacot2018Neural,
  author    = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  title     = {Neural {T}angent {K}ernel: Convergence and {G}eneralization in {N}eural {N}etworks},
  booktitle = {Advances in neural information processing systems},
  year      = {2018},
  pages     = {8571--8580},
}
@Article{mei2018mean,
  author    = {Mei, Song and Montanari, Andrea and Nguyen, Phan-Minh},
  title     = {A {M}ean {F}ield {V}iew of the {L}andscape of {T}wo-layer {N}eural {N}etworks},
  journal   = {Proceedings of the National Academy of Sciences},
  year      = {2018},
  volume    = {115},
  number    = {33},
  pages     = {E7665--E7671},
  publisher = {National Acad Sciences},
}
@InProceedings{
SmithBarrett2021ImplicitRegularSGD,
title={On the Origin of Implicit Regularization in Stochastic Gradient Descent},
author={Samuel L Smith and Benoit Dherin and David Barrett and Soham De},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=rq_Qr0c1Hyo}
}
@InProceedings{
Barrett2021implicitGD,
title={Implicit Gradient Regularization},
author={David Barrett and Benoit Dherin},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=3q5IqUrkcF}
}
@article{FengLiLiu2018semigroups,
  title={Semigroups of stochastic gradient descent and online principal component analysis: properties and diffusion approximations},
  author={Feng, Yuanyuan and Li, Lei and Liu, Jian-Guo},
  journal={Communications in Mathematical Sciences},
  volume={16},
  number={3},
  year={2018}
}
@article{Kubo1966Fluctuation,
  title={The fluctuation-dissipation theorem},
  author={Kubo, Rep},
  journal={Reports on progress in physics},
  volume={29},
  number={1},
  pages={255},
  year={1966},
  publisher={IOP Publishing}
}
@InProceedings{Yaida2019Fluctuation,
  author    = {Sho Yaida},
  title     = {Fluctuation-dissipation relations for stochastic gradient descent},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=SkNksoRctQ},
  timestamp = {Thu, 25 Jul 2019 14:25:54 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/Yaida19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{MandtMatthew2017SGDApproximateBayesian,
  title={Stochastic Gradient Descent as Approximate Bayesian Inference},
  author={Mandt, Stephan and Hoffman, Matthew D and Blei, David M},
  journal={Journal of Machine Learning Research},
  volume={18},
  pages={1--35},
  year={2017}
}
